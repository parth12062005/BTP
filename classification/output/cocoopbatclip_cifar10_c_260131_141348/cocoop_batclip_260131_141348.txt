[26/01/31 14:13:48] [conf.py:  424]: PyTorch Version: torch=2.2.1, cuda=12.1, cudnn=8902
[26/01/31 14:13:48] [conf.py:  425]: ADACONTRAST:
  ALPHA: 1.0
  BETA: 1.0
  CE_SUP_TYPE: weak_strong
  CE_TYPE: standard
  CONTRAST_TYPE: class_aware
  DIST_TYPE: cosine
  ETA: 1.0
  NUM_NEIGHBORS: 10
  QUEUE_SIZE: 16384
  REFINE_METHOD: nearest_neighbors
BN:
  ALPHA: 0.1
CKPT_DIR: ./ckpt
CLIP:
  FREEZE_TEXT_ENCODER: False
  PRECISION: fp32
  PROMPT_MODE: custom
  PROMPT_PATH: datasets/cupl_prompts/CuPL_ImageNet_prompts.json
  PROMPT_TEMPLATE: ['a photo of a {}.']
CMF:
  ALPHA: 0.99
  GAMMA: 0.99
  Q: 0.005
  TYPE: lp
CONTRAST:
  MODE: all
  PROJECTION_DIM: 128
  TEMPERATURE: 0.1
CORRUPTION:
  DATASET: cifar10_c
  NUM_EX: -1
  SEVERITY: [1, 2, 3, 4, 5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
COTTA:
  AP: 0.92
  RST: 0.01
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
DETERMINISM: False
DEYO:
  AUG_TYPE: patch
  COLUMN_START: 56
  MARGIN: 0.5
  OCCLUSION_SIZE: 112
  PATCH_LEN: 4
  PLPD: 0.2
  REWEIGHT_ENT: True
  REWEIGHT_PLPD: True
  ROW_START: 56
EATA:
  D_MARGIN: 0.05
  FISHER_ALPHA: 2000.0
  MARGIN_E0: 0.4
GTTA:
  LAMBDA_MIXUP: 0.3333333333333333
  PRETRAIN_STEPS_ADAIN: 20000
  STEPS_ADAIN: 1
  USE_STYLE_TRANSFER: False
LAME:
  AFFINITY: rbf
  FORCE_SYMMETRY: False
  KNN: 5
  SIGMA: 1.0
LOG_DEST: cocoop_batclip_260131_141348.txt
LOG_TIME: 260131_141348
MIXED_PRECISION: False
MODEL:
  ADAPTATION: cocoopbatclip
  ARCH: ViT-B-16
  CKPT_PATH: checkpoints/cocoop_cifar10_best.pth
  EPISODIC: False
  RESET_AFTER_NUM_UPDATES: 0
  USE_CLIP: True
  WEIGHTS: openai
M_TEACHER:
  MOMENTUM: 0.999
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: AdamW
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.01
PRINT_EVERY: -1
RMT:
  LAMBDA_CE_SRC: 1.0
  LAMBDA_CE_TRG: 1.0
  LAMBDA_CONT: 1.0
  NUM_SAMPLES_WARM_UP: 50000
RNG_SEED: 1
ROID:
  MOMENTUM_PROBS: 0.9
  MOMENTUM_SRC: 0.99
  TEMPERATURE: 0.3333333333333333
  USE_CONSISTENCY: True
  USE_PRIOR_CORRECTION: True
  USE_WEIGHTING: True
ROTTA:
  ALPHA: 0.05
  LAMBDA_T: 1.0
  LAMBDA_U: 1.0
  MEMORY_SIZE: 64
  NU: 0.001
  UPDATE_FREQUENCY: 64
RPL:
  Q: 0.8
SANTA:
  LAMBDA_CE_TRG: 1.0
  LAMBDA_CONT: 1.0
SAR:
  RESET_CONSTANT_EM: 0.2
SAVE_DIR: ./output/cocoopbatclip_cifar10_c_260131_141348
SETTING: reset_each_shift
SOURCE:
  NUM_SAMPLES: -1
  NUM_WORKERS: 4
  PERCENTAGE: 1.0
TEST:
  BATCH_SIZE: 64
  DEBUG: False
  DELTA_DIRICHLET: 0.0
  NUM_WORKERS: 4
  N_AUGMENTATIONS: 32
  WINDOW_LENGTH: 1
TPT:
  CLASS_TOKEN_POS: end
  CTX_INIT: a_photo_of_a
  LAMBDA_ENT: 0.0
  N_CTX: 4
  SELECTION_P: 0.1
[26/01/31 14:13:48] [factory.py:  202]: Loading pretrained ViT-B-16 from OpenAI.
[26/01/31 14:13:53] [custom_clip.py:   72]: Initializing the context with given words: [a_photo_of_a]
[26/01/31 14:13:53] [custom_clip.py:   98]: Initial context: "a photo of a"
[26/01/31 14:13:53] [custom_clip.py:   99]: Number of context words (tokens): 4
[26/01/31 14:13:53] [model.py:  461]: Successfully restored pre-trained soft prompt (CoOp) for CoCoOp-BATCLIP
[26/01/31 14:13:53] [base.py:  186]: #Trainable/total parameters: 100,896/149,656,096 	 Ratio: 0.067% 
[26/01/31 14:13:53] [test_time.py:   44]: Successfully prepared test-time adaptation method: cocoopbatclip
[26/01/31 14:13:53] [test_time.py:   55]: Using cifar10_c with the following domain sequence: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
[26/01/31 14:13:53] [test_time.py:   76]: resetting model
[26/01/31 14:13:53] [test_time.py:  104]: Using the following data transformation:
Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=True)
    CenterCrop(size=(224, 224))
    <function _convert_to_rgb at 0x7fb9aa8deac0>
    ToTensor()
)
